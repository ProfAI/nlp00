{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "glove.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProfAI/nlp00/blob/master/09%20-%20Word%20embedding%20e%20Word2Vec/glove.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkdUZTRZBP80"
      },
      "source": [
        "# GloVe\n",
        "Il modello **GloVe (Global Vectors for Word Representation)** è un metodo non supervisionato per l'apprendimento della rappresentazione vettoriale delle parole. La prima versione di GloVe è stata creata nei laboratori di NLP di Standford nel 2014, i quali hanno messo a disposizione il modello pre-addestrato sull'intero corpus di testo di Wikipedia, con qualcosa come 6 miliardi di parole. In questo notebook utilizzeremo il modello pre-addestrato per creare lo strato di embedding di una rete neurale per classificare la polarità di recensioni di film utilizzando l'IMDB Movie Reviews Dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgewpERwNiiS"
      },
      "source": [
        "## Prepariamo i dati"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_xAZpjJqa5L"
      },
      "source": [
        "In precedenza abbiamo visto come scaricare e preprocessare l'IMDB Movie Reviews Dataset, Keras mette a disposizione tale dataset già preprocessato.\n",
        "<br>**ATTENZIONE**<br>\n",
        "Se caricando il dataset ottieni questo errore:<br>\n",
        "*ValueError: Object arrays cannot be loaded when allow_pickle=False*\n",
        "<br>\n",
        "questo è casuato da un bug nell'ultima versione di keras, per correggerlo esegui il downgrade di numpy usando la cella di codice qui sotto e riavvia il kernel (su Colaboratory seleziona Runtime dalla barra dei comandi e clicca su Restart Runtime)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-ixlnXETWRF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "268279f4-4d99-4516-d5a0-a1619e282994"
      },
      "source": [
        "!pip install numpy==1.16.2"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.16.2 in /usr/local/lib/python3.7/dist-packages (1.16.2)\n",
            "Requirement already up-to-date: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.16.2)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XT-U5zhnSZZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6c9277a-6540-4c9c-973a-18f1cccf4676"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data()\n",
        "\n",
        "print(X_train[0][:10])"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hGPDrLVOGzY"
      },
      "source": [
        "Ogni riga della lista con le features corrisponde ad una frase, ogni colonna contiene l'indice di una parola all'interno del vocabolario dell'intero corpus di testo. Il vettore con il target contiene un unico valore che può essere 0 per una recensione negativa o 1 per una recensione positiva.<br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scUEh5saQ-nS"
      },
      "source": [
        "Proviamo a ricostruire la prima frase dagli indici, just for fun :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ-psRlaQWXJ"
      },
      "source": [
        "word_index = imdb.get_word_index()\n",
        "word_index = {k:(v+3) for k,v in word_index.items()}\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2\n",
        "word_index[\"<UNUSED>\"] = 3"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKBJkRltJ3vj",
        "outputId": "14cbe682-051c-4259-ca51-914be8ae88db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "index_word = {value:key for key,value in word_index.items()}\n",
        "print(' '.join(index_word[id] for id in X_train[0] ))"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5nUyvMQRV5I"
      },
      "source": [
        "Per rendere le features un buon input per il nostro modello dobbiamo fare in modo che ogni frase abbia la stessa lunghezza, per farlo possiamo usare la funzione *pad_sequences(text)* di keras, che riduce tutte le frasi ad una lunghezza prefissata troncando quelle troppo lunghe e aggiungendo degli zeri a quelle troppo brevi. Usiamo una lunghezza comune di 50 parole."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkJLREGvPBtY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "566e136c-465c-4db5-ca28-58caa22bb0d2"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "maxlen = 50\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen = maxlen)\n",
        "X_test = pad_sequences(X_test, maxlen = maxlen)\n",
        "\n",
        "X_train.shape"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6bjrSQOPsUr"
      },
      "source": [
        "Adesso i dati sono pronti."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScqnikSMPu1I"
      },
      "source": [
        "## Carichiamo il modello GloVe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0hKGO1-qK2J"
      },
      "source": [
        "Possiamo scaricare il modello pre-addestrato [da questo link](http://nlp.stanford.edu/data/glove.6B.zip). Se utilizzi Google Colab o comunque hai wget installato sul tuo computer esegui pure la cella di codice qui sotto per scaricare il dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8d5wxXRBO5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ca45a32-8c52-408d-af65-e4784d61f232"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-24 08:36:09--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-04-24 08:36:10--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-04-24 08:36:10--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  4.86MB/s    in 2m 42s  \n",
            "\n",
            "2021-04-24 08:38:53 (5.06 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p9aAzJiqUwg"
      },
      "source": [
        "Ed estraiamo il file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtvH2-kRRoHK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "577dc306-d26e-4bea-8d8c-a48eb3535e3a"
      },
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKObUykSGrvX"
      },
      "source": [
        "Lo zip contiene 4 file differenti, ognuno dei quali con un numero di dimensioni differente, 50, 100, 200 e 300. Leggiamo la prima riga del file con 50 dimensioni per comprendere come questo è strutturato."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCMijSPqG0Rj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4291d9c-e06a-4ea9-8520-98bb52809379"
      },
      "source": [
        "with open(\"glove.6B.50d.txt\") as file:\n",
        "  for line in file.readlines():\n",
        "    print(line)\n",
        "    break"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the 0.418 0.24968 -0.41242 0.1217 0.34527 -0.044457 -0.49688 -0.17862 -0.00066023 -0.6566 0.27843 -0.14767 -0.55677 0.14658 -0.0095095 0.011658 0.10204 -0.12792 -0.8443 -0.12181 -0.016801 -0.33279 -0.1552 -0.23131 -0.19181 -1.8823 -0.76746 0.099051 -0.42125 -0.19526 4.0071 -0.18594 -0.52287 -0.31681 0.00059213 0.0074449 0.17778 -0.15897 0.012041 -0.054223 -0.29871 -0.15749 -0.34758 -0.045637 -0.44251 0.18785 0.0027849 -0.18411 -0.11514 -0.78581\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KBuui-CGyWi"
      },
      "source": [
        "Come vedi ogni riga corrisponde all'embedding per una determianta parola, il primo elemento della riga è la parola, i restanti solo i valori degli embedding. Alla luce di ciò definiamo una funzione per caricare gli embedding all'iterno di un dizionario la cui chiave è la parola. Usiamo il file con 100 dimensioni."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MKOdv89OqgP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0d256c9-5202-4fbc-8d56-693f0bac4124"
      },
      "source": [
        "def load_embedding(filename):\n",
        "  \n",
        "  with open(filename) as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "  embedding = dict()\n",
        "  \n",
        "  for line in lines:\n",
        "    parts = line.split()\n",
        "    embedding[parts[0]] = np.asarray(parts[1:])\n",
        "    \n",
        "  return embedding\n",
        "\n",
        "raw_embedding = load_embedding('glove.6B.100d.txt')\n",
        "raw_embedding[\"man\"]"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0.37293', '0.38503', '0.71086', '-0.65911', '-0.0010128',\n",
              "       '0.92715', '0.27615', '-0.056203', '-0.24294', '0.24632',\n",
              "       '-0.18449', '0.31398', '0.48983', '0.09256', '0.32958', '0.15056',\n",
              "       '0.57317', '-0.18529', '-0.52277', '0.46191', '0.92038',\n",
              "       '0.031001', '-0.16246', '-0.40567', '0.78621', '0.57722',\n",
              "       '-0.53501', '-0.68228', '0.16987', '0.3631', '-0.071773',\n",
              "       '0.47233', '0.027806', '-0.14951', '0.17543', '-0.37573',\n",
              "       '-0.78517', '0.58171', '0.86859', '0.031445', '-0.45897',\n",
              "       '-0.040917', '0.95897', '-0.16975', '0.13045', '0.27434',\n",
              "       '-0.069485', '0.022402', '0.24977', '-0.21536', '-0.32406',\n",
              "       '-0.39867', '0.68613', '1.7923', '-0.37848', '-2.2477', '-0.77025',\n",
              "       '0.46582', '1.2411', '0.57756', '0.41151', '0.84328', '-0.54259',\n",
              "       '-0.16715', '0.73927', '-0.093477', '0.90278', '0.50889',\n",
              "       '-0.50031', '0.26451', '0.15443', '-0.29432', '0.10906',\n",
              "       '-0.26667', '0.35438', '0.049079', '0.18018', '-0.5859',\n",
              "       '-0.55542', '-0.28987', '0.74278', '0.3453', '-0.028757',\n",
              "       '-0.22646', '-1.3113', '-0.5719', '-0.52306', '-0.1267',\n",
              "       '-0.098678', '-0.53463', '0.28607', '-0.37501', '0.45742',\n",
              "       '0.045975', '-0.24675', '0.045656', '-0.38302', '-0.93711',\n",
              "       '0.039138', '-0.53911'], dtype='<U10')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NpywazVH2hq"
      },
      "source": [
        "Adesso dobbiamo trasformare il dizionario in una matrice, in cui ogni riga rappresenta contiene la rappresentazione vettoriale della parola che si trova alla stessa posizione all'interno del vocabolario dell'intero corpus di testo. Keras ci mette a disposizione anche il vocabolario già creato per questo dataset. possiamo ottenerlo con la funzione *.get_word_index()*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44IpAdCRKFWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5436674c-e498-469e-df4c-5bff56cfe1a5"
      },
      "source": [
        "word_index = imdb.get_word_index()\n",
        "word_index[\"man\"]"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "129"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNNE28PsKLaX"
      },
      "source": [
        "Definiamo la funzione per creare la matrie ed utilizziamola."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doMODtsZReBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb220273-7c16-44b6-f801-e0dabc0e95cb"
      },
      "source": [
        "def get_weight_matrix(embedding, word_index):\n",
        "  \n",
        "  vocab_size = len(word_index)+3\n",
        "  \n",
        "  weight_matrix = np.zeros((vocab_size, 100))\n",
        "\n",
        "  for word, i in word_index.items():\n",
        "    vector = embedding.get(word)\n",
        "    if vector is not None:\n",
        "      weight_matrix[i] = vector\n",
        "      \n",
        "  return weight_matrix\n",
        "\n",
        "embedding_vectors = get_weight_matrix(raw_embedding, word_index)\n",
        "embedding_vectors.shape"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(88587, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y23OaHbKtbn"
      },
      "source": [
        "# Creiamo la rete\n",
        "Cominciamo creando lo strato di embedding della rete, i primi due parametri saranno il numero di parole e il numero di dimensioni, passiamo gli embeddings già calcolati all'interno del parametro *weights* e settiamo il parametro *trainable* a False per indicare di non modificare questo strato della rete durante l'addestramento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va046uMMRegc"
      },
      "source": [
        "from keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(embedding_vectors.shape[0], 100, weights=[embedding_vectors], trainable=False, input_length=maxlen)"
      ],
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVGu3IIhXuuw"
      },
      "source": [
        "Ora creiamo la nostra rete neurale aggiungendo al primo strato lo strato di embedding appena creato, usiamo la classe *Flatten* di Keras per spacchettare la matrice con il word embedding in un unico vettore che unisce le righe della matrice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU90syz1RuVT"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "\n",
        "model = Sequential()\n",
        "model.add(embedding_layer)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3d4wQO9X0OB"
      },
      "source": [
        "Compiliamo il modello ed avviamo l'addestramento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w3mIiB3QAUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd6f3391-6f5a-4239-84dc-fd6d56358432"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size=512, epochs=10)"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "49/49 [==============================] - 1s 4ms/step - loss: 0.7344 - accuracy: 0.5169\n",
            "Epoch 2/10\n",
            "49/49 [==============================] - 0s 5ms/step - loss: 0.6757 - accuracy: 0.5826\n",
            "Epoch 3/10\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6491 - accuracy: 0.6200\n",
            "Epoch 4/10\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6386 - accuracy: 0.6335\n",
            "Epoch 5/10\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6244 - accuracy: 0.6484\n",
            "Epoch 6/10\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6170 - accuracy: 0.6607\n",
            "Epoch 7/10\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6092 - accuracy: 0.6641\n",
            "Epoch 8/10\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.6027 - accuracy: 0.6746\n",
            "Epoch 9/10\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.5953 - accuracy: 0.6805\n",
            "Epoch 10/10\n",
            "49/49 [==============================] - 0s 4ms/step - loss: 0.5876 - accuracy: 0.6928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faed6f29410>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHSNuihGZhBW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a1abb17-71bd-4d5c-8a20-2fd52732f3ac"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 2s 2ms/step - loss: 0.6996 - accuracy: 0.5716\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6996147632598877, 0.5715600252151489]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIhX1KUJZmU_"
      },
      "source": [
        "Lo strato di embedding funziona correttamente, ma il risultato è piuttosto scarso, perché ? Perché utilizzare l'embedding senza tener conto della relazione temporale all'interno di una sequenza (come può essere una frase) è una cosa abbastanza inutile. Per tener conto delle informazioni sequenziali dobbiamo usare degli strati ricorrenti."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrgQfvmZZZuy"
      },
      "source": [
        "# Usiamo uno Strato Ricorrente\n",
        "Le Reti Neurali Ricorrenti (RNN) saranno l'argomento della prossima sezione, qui vediamo semplicemente come varia il risultato utilizzandole insieme all'embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q5e8lyHRQ4J"
      },
      "source": [
        "from keras.layers import SimpleRNN\n",
        "\n",
        "model = Sequential()\n",
        "#model.add(Embedding(num_words, 50))\n",
        "model.add(embedding_layer)\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rf5PVihdUnD"
      },
      "source": [
        "Come algoritmo di ottimizzazione usiamo l'RMSProp che dovrebbe portare a risultati migliori per le reti ricorrenti, siccome è più lento a convergere rispetto all'ADAM aumentiamo il numero di epoche dell'addestramento a 20."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fDXsPsCWd0N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c3fba9b-c41a-48e7-b8ae-7754ba431f5d"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, batch_size=512, epochs=20)"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "49/49 [==============================] - 3s 32ms/step - loss: 0.7241 - accuracy: 0.5050\n",
            "Epoch 2/20\n",
            "49/49 [==============================] - 2s 31ms/step - loss: 0.6880 - accuracy: 0.5411\n",
            "Epoch 3/20\n",
            "49/49 [==============================] - 2s 31ms/step - loss: 0.6796 - accuracy: 0.5569\n",
            "Epoch 4/20\n",
            "49/49 [==============================] - 1s 30ms/step - loss: 0.6718 - accuracy: 0.5724\n",
            "Epoch 5/20\n",
            "49/49 [==============================] - 2s 31ms/step - loss: 0.6672 - accuracy: 0.5837\n",
            "Epoch 6/20\n",
            "49/49 [==============================] - 2s 31ms/step - loss: 0.6604 - accuracy: 0.5947\n",
            "Epoch 7/20\n",
            "49/49 [==============================] - 2s 32ms/step - loss: 0.6581 - accuracy: 0.6008\n",
            "Epoch 8/20\n",
            "49/49 [==============================] - 1s 30ms/step - loss: 0.6523 - accuracy: 0.6040\n",
            "Epoch 9/20\n",
            "49/49 [==============================] - 2s 31ms/step - loss: 0.6471 - accuracy: 0.6157\n",
            "Epoch 10/20\n",
            "49/49 [==============================] - 1s 30ms/step - loss: 0.6429 - accuracy: 0.6172\n",
            "Epoch 11/20\n",
            "49/49 [==============================] - 2s 31ms/step - loss: 0.6412 - accuracy: 0.6278\n",
            "Epoch 12/20\n",
            "49/49 [==============================] - 2s 31ms/step - loss: 0.6384 - accuracy: 0.6286\n",
            "Epoch 13/20\n",
            "49/49 [==============================] - 1s 30ms/step - loss: 0.6383 - accuracy: 0.6272\n",
            "Epoch 14/20\n",
            "49/49 [==============================] - 2s 31ms/step - loss: 0.6304 - accuracy: 0.6363\n",
            "Epoch 15/20\n",
            "49/49 [==============================] - 2s 31ms/step - loss: 0.6344 - accuracy: 0.6368\n",
            "Epoch 16/20\n",
            "49/49 [==============================] - 2s 31ms/step - loss: 0.6267 - accuracy: 0.6417\n",
            "Epoch 17/20\n",
            "49/49 [==============================] - 2s 31ms/step - loss: 0.6258 - accuracy: 0.6456\n",
            "Epoch 18/20\n",
            "49/49 [==============================] - 2s 31ms/step - loss: 0.6230 - accuracy: 0.6484\n",
            "Epoch 19/20\n",
            "49/49 [==============================] - 2s 32ms/step - loss: 0.6183 - accuracy: 0.6505\n",
            "Epoch 20/20\n",
            "49/49 [==============================] - 1s 31ms/step - loss: 0.6177 - accuracy: 0.6540\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fae63887590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbWVLQyaWkN8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "6734685f-cecf-4cb1-b1df-15d997503ba9"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-187-acc519fcce62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0mbase_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_api_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m     \u001b[0mversion_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1342\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1343\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'evaluate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2590\u001b[0m     \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2591\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2592\u001b[0;31m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[1;32m   2593\u001b[0m                          \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2594\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
            "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ]
    }
  ]
}